////
This guide is maintained in the main Quarkus repository
and pull requests should be submitted there:
https://github.com/quarkusio/quarkus/tree/main/docs/src/main/asciidoc
////
= Quarkus - Getting Started to SmallRye Reactive Messaging with Apache Kafka

include::./attributes.adoc[]

This guide demonstrates how your Quarkus application can utilize SmallRye Reactive Messaging to interact with Apache Kafka.

== Prerequisites

To complete this guide, you need:

* less than 15 minutes
* an IDE
* JDK 11+ installed with `JAVA_HOME` configured appropriately
* Apache Maven {maven-version}
* GraalVM installed if you want to run in native mode.

== Architecture

In this guide, we are going to generate (random) prices in one component.
These prices are written in a Kafka topic (`prices`).
A second component reads from the `prices` Kafka topic and apply some magic conversion to the price.
The result is sent to an in-memory channel consumed by a JAX-RS resource.
The data is sent to a browser using server-sent events.

image::kafka-guide-architecture.png[alt=Architecture, align=center]

== Solution

We recommend that you follow the instructions in the next sections and create the application step by step.
However, you can go right to the completed example.

Clone the Git repository: `git clone {quickstarts-clone-url}`, or download an {quickstarts-archive-url}[archive].

The solution is located in the `kafka-quickstart` {quickstarts-tree-url}/kafka-quickstart[directory].

== Creating the Maven Project

First, we need a new project.
Create a new project with the following command:

[source,bash,subs=attributes+]
----
mvn io.quarkus:quarkus-maven-plugin:{quarkus-version}:create \
    -DprojectGroupId=org.acme \
    -DprojectArtifactId=kafka-quickstart \
    -DclassName="org.acme.kafka.PriceResource" \
    -Dpath="/prices" \
    -Dextensions="resteasy-reactive,resteasy-reactive-jackson,smallrye-reactive-messaging-kafka"
cd kafka-quickstart
----

This command generates a Maven project, importing the Reactive Messaging and Kafka connector extensions.

If you already have your Quarkus project configured, you can add the `smallrye-reactive-messaging-kafka`
and `resteasy-jackson` extensions to your project by running the following command in your project base directory:

[source,bash]
----
./mvnw quarkus:add-extension -Dextensions="smallrye-reactive-messaging-kafka,resteasy-reactive-jackson"
----

This will add the following to your `pom.xml`:

[source,xml]
----
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-resteasy-reactive-jackson</artifactId>
</dependency>
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>
</dependency>
----

[TIP]
.Dev Services
====
No need to start a Kafka broker when using the dev mode or for tests.
Quarkus starts a broker for you automatically.
See xref:kafka-dev-services.adoc[Dev Services for Kafka] for details.
====

== The price object

Create the `src/main/java/org/acme/kafka/Price.java` file, with the following content:

[source,java]
----
package org.acme.kafka;

public class Price {

    public double value;
    public String currency;

    public Price() { }

    public Price(double value, String currency) {
        this.value = value;
        this.currency = currency;
    }
}
----

JSON representation of `Price` objects will be used in messages sent to the Kafka topic
and also server-sent events sent to browser clients.

Quarkus has built-in capabilities to deal with JSON Kafka messages.
In a following section we will create serializer/deserializer classes for Jackson.

== The price generator

Create the `src/main/java/org/acme/kafka/PriceGenerator.java` file, with the following content:

[source,java]
----
package org.acme.kafka;

import java.time.Duration;
import java.util.Random;

import javax.enterprise.context.ApplicationScoped;

import io.smallrye.mutiny.Multi;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

/**
 * A bean producing random prices every 5 seconds.
 * The prices are written to a Kafka topic (prices).
 * The Kafka configuration is specified in the application configuration.
 */
@ApplicationScoped
public class PriceGenerator {

    private Random random = new Random();

    @Outgoing("generated-price")                        // <1>
    public Multi<Integer> generate() {                  // <2>
        return Multi.createFrom().ticks().every(Duration.ofSeconds(5))
                .onOverflow().drop()
                .map(tick -> new Price(random.nextInt(100), "$"));
    }

}
----
<1> Instruct Reactive Messaging to dispatch the items from returned stream to `generated-price`.
<2> The method returns a Mutiny _stream_ (`Multi`) emitting a `Price` object containing random prices, every 5 seconds.

The method returns a _Reactive Stream_.
The generated items are sent to the stream named `generated-price`.
This stream is mapped to Kafka using the `application.properties` file that we will create soon.

== The price converter

The price converter reads the prices from Kafka, and transforms them.
Create the `src/main/java/org/acme/kafka/PriceConverter.java` file with the following content:

[source, java]
----
package org.acme.kafka;

import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import javax.enterprise.context.ApplicationScoped;

/**
 * A bean consuming data from the "prices" Kafka topic and applying some conversion.
 * The result is pushed to the "my-data-stream" stream which is an in-memory stream.
 */
@ApplicationScoped
public class PriceConverter {

    private static final double CONVERSION_RATE = 0.88;

    @Incoming("prices")                                     // <1>
    @Outgoing("my-data-stream")                             // <2>
    public Price process(Price priceInUsd) {
        return new Price(priceInUsd.value * CONVERSION_RATE, "â‚¬");
    }

}
----
<1> Indicates that the method consumes the items from the `prices` topic
<2> Indicates that the objects returned by the method are sent to the `my-data-stream` stream

The `process` method is called for every Kafka _record_ from the `prices` topic (configured in the application configuration).
Every result is sent to the `my-data-stream` in-memory stream.

== The price resource

Let's bind our stream to a JAX-RS resource and send events to clients.
Create the `src/main/java/org/acme/kafka/PriceResource.java` file with the following content:

[source,java]
----
package org.acme.kafka;

import javax.inject.Inject;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.reactivestreams.Publisher;

/**
 * A simple resource retrieving the prices topic and sending the items to a server sent event.
 */
@Path("/")
public class PriceResource {

    @Inject
    @Channel("my-data-stream") Publisher<Price> prices; // <1>

    @GET
    @Path("/prices")
    @Produces(MediaType.SERVER_SENT_EVENTS) // <2>
    public Publisher<Price> stream() { // <3>
        return prices;
    }
}
----
<1> Injects the `my-data-stream` channel using the `@Channel` qualifier
<2> Indicates that the content is sent using `Server Sent Events`
<3> Returns the stream (_Reactive Stream_)

== JSON serialization via Jackson

Finally, we will configure JSON serialization for messages using Jackson.
Quarkus provides default implementations for Kafka serializer/deserializer pairs using Jackson `ObjectMapper`.
`ObjectMapperSerializer` can be used to serialize all objects via Jackson.
For the corresponding deserializer class, we need to create a subclass of `ObjectMapperDeserializer`.

So, let's create `src/main/java/org/acme/kafka/PriceDeserializer.java`

[source,java]
----
package org.acme.kafka;

import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class PriceDeserializer extends ObjectMapperDeserializer<Price> {
    public PriceDeserializer() {
        // pass the class to the parent.
        super(Price.class);
    }
}
----

[TIP]
====
.Message serialization in Kafka
In this example we used Jackson to serialize/deserialize Kafka messages.
For more options on message serialization see <<kafka-serialization>>.

We strongly suggest adopting a contract-first approach using a schema registry.
To learn more about how to use Apache Kafka with the schema registry and Avro follow the link:kafka-schema-registry-avro.adoc[Using Apache Kafka with Schema Registry and Avro] guide.
====

== Configuring the Kafka connector

We need to configure the Kafka connector.
This is done in the `application.properties` file.
The keys are structured as follows:

`mp.messaging.[outgoing|incoming].{channel-name}.property=value`

The `channel-name` segment must match the value set in the `@Incoming` and `@Outgoing` annotation:

* `generated-price` -> Kafka topic in which we write the prices
* `prices` -> Kafka topic from which we read the prices

[source,properties]
----

# Configure the outgoing Kafka topic (we write to it)
mp.messaging.outgoing.generated-price.connector=smallrye-kafka
mp.messaging.outgoing.generated-price.topic=prices
mp.messaging.outgoing.generated-price.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer

# Configure the incoming Kafka topic (we read from it)
mp.messaging.incoming.prices.connector=smallrye-kafka
mp.messaging.incoming.prices.topic=prices
mp.messaging.incoming.prices.value.deserializer=org.acme.kafka.PriceDeserializer

----

This configuration does not set the Kafka _bootstrap.servers_.
Quarkus starts a Kafka broker automatically and configures the application.
See xref:kafka-dev-services.adoc[Dev Services for Kafka] for more details.

More details about this configuration is available on the https://kafka.apache.org/documentation/#producerconfigs[Producer configuration] and https://kafka.apache.org/documentation/#consumerconfigs[Consumer configuration] section from the Kafka documentation. These properties are configured with the prefix `kafka`. An exhaustive list of configuration properties is available in <<kafka-configuration>>.

NOTE: What about `my-data-stream`? This is an in-memory stream, not connected to a message broker.

== The HTML page

Final touch, the HTML page reading the converted prices using SSE.

Create the `src/main/resources/META-INF/resources/prices.html` file, with the following content:

[source, html]
----

<!DOCTYPE html> <html lang="en"> <head> <meta charset="UTF-8"> <title>Prices</title>

    <link rel="stylesheet" type="text/css"
          href="https://cdnjs.cloudflare.com/ajax/libs/patternfly/3.24.0/css/patternfly.min.css">
    <link rel="stylesheet" type="text/css"
          href="https://cdnjs.cloudflare.com/ajax/libs/patternfly/3.24.0/css/patternfly-additions.min.css">
</head>
<body>
<div class="container">

    <h2>Last price</h2>
    <div class="row">
    <p class="col-md-12">The last price is <strong><span id="value">N/A</span>&nbsp;<span id="currency"></span></strong>.</p>
    </div>
</div>
</body>
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script>
    var source = new EventSource("/prices");
    source.onmessage = function (event) {
        var json = JSON.parse(event.data);
        document.getElementById("value").innerHTML = json.value;
        document.getElementById("currency").innerHTML = json.currency;
    };
</script>
</html>
----

Nothing spectacular here.
On each received price, it updates the page.

== Get it running

You just need to run the application using:

[source,bash]
----
./mvnw quarkus:dev
----

Open `http://localhost:8080/prices.html` in your browser.

== Running in JVM or Native mode

When not running in dev or test mode, you will need to start your Kafka broker.
You can follow the instructions from the https://kafka.apache.org/quickstart[Apache Kafka web site] or create a `docker-compose.yaml` file with the following content:

[source, yaml]
----
version: '2'

services:

  zookeeper:
    image: quay.io/strimzi/kafka:0.23.0-kafka-2.8.0
    command: [
      "sh", "-c",
      "bin/zookeeper-server-start.sh config/zookeeper.properties"
    ]
    ports:
      - "2181:2181"
    environment:
      LOG_DIR: /tmp/logs

  kafka:
    image: quay.io/strimzi/kafka:0.23.0-kafka-2.8.0
    command: [
      "sh", "-c",
      "bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT}"
    ]
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      LOG_DIR: "/tmp/logs"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
----

Once created, run `docker-compose up`.

NOTE: This is a development cluster, do not use in production.

You can build and run the application in JVM mode with:

[source, bash]
----
./mvnw package
java -jar target/quarkus-app/quarkus-run.jar
----

NOTE: By default, the application tries to connect to a Kafka broker listening at `localhost:9092`.
You can configure the bootstrap server using: `java -Dkafka.bootstrap.servers=... -jar target/quarkus-app/quarkus-run.jar`

You can build and run the native executable with:

[source,bash]
----
./mvnw package -Pnative
./target/kafka-quickstart-1.0.0-SNAPSHOT-runner -Dkafka.bootstrap.servers=localhost:9092
----

== Going further

This guide has shown how you can interact with Kafka using Quarkus.
It utilizes SmallRye Reactive Messaging to build data streaming applications.

If you want to go further check the documentation of https://smallrye.io/smallrye-reactive-messaging[SmallRye Reactive Messaging], the implementation used in Quarkus.

For the exhaustive list of features and configuration options check the
xref:kafka.adoc[Reference guide for Apache Kafka Extension].
